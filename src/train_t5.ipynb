{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "\n",
    "checkpoint = \"cjvt/t5-sl-small\"\n",
    "#checkpoint = \"cjvt/t5-sl-large\"\n",
    "\n",
    "max_len = 512 # num of input/output tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joze/Documents/sola/obdelava_naravnega_jezika/nlp-course-taklemamo/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[7477,    1]]), 'attention_mask': tensor([[1, 1]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer([\"test\"], return_tensors=\"pt\")#👍"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import pandas as pd\n",
    "\n",
    "class ParaDataset(Dataset):\n",
    "\n",
    "  def __init__(self, fpath, tokenizer, prefix, max_len=512):\n",
    "    super().__init__()\n",
    "    self.raw_data = self._load(fpath)\n",
    "    self.tokenizer = tokenizer\n",
    "    self.prefix = prefix\n",
    "    self.max_len = max_len\n",
    "\n",
    "    self.inputs, self.targets = self._preprocess()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.raw_data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    out = {k:v[index] for k,v in self.inputs.items()}\n",
    "    out[\"labels\"] = self.targets.input_ids[index]\n",
    "    return out\n",
    "\n",
    "  def _load(self, fpath):\n",
    "    return pd.read_csv(fpath, sep=\"\\t\", names=[\"paragraph\", \"paraphrase\"])\n",
    "\n",
    "  def _preprocess(self):\n",
    "    return self._tokenize(self.raw_data.paragraph), self._tokenize(self.raw_data.paraphrase, prefix=False)\n",
    "\n",
    "  def _tokenize(self, text_list, prefix=True):\n",
    "    return self.tokenizer(\n",
    "        [self.prefix + text if prefix else text for text in text_list],\n",
    "        truncation=True, padding=\"max_length\", \n",
    "        max_length=self.max_len, return_tensors=\"pt\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amsterdam - Le nekaj mesecev potem, ko so nizo...</td>\n",
       "      <td>Amsterdam - Le nekaj mesecev po tem, ko so niz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"S trenerjem sva načrtovala uvrstitev v najbol...</td>\n",
       "      <td>\"S trenerjem sva načrtovala uvrstitev med najb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Najprej zato, ker znajo gledalcem, ki se jih j...</td>\n",
       "      <td>Najprej zato, ker znajo gledalcem ponuditi, ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Izidi: 1. kolo - skupina A: ZRJ - Grčija 83:72...</td>\n",
       "      <td>: Rezultati 1 kolo - skupina A: FRY - Grčija 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tekmovanje se bo pravzaprav začelo že danes z ...</td>\n",
       "      <td>Tekmovanje se bo pravzaprav začelo danes z ura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11306</th>\n",
       "      <td>Bistvo vsega ni naše telo, temveč telo tehnolo...</td>\n",
       "      <td>Bistvo vsega ni naše telo, ampak telo tehnolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11307</th>\n",
       "      <td>Crowley je bil tudi sam umetnik. Za njim je os...</td>\n",
       "      <td>Crowley sam je bil umetnik, ki je zapustil pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11308</th>\n",
       "      <td>Vsi, ki jih \"prerok Horusovega eona\" tako ali ...</td>\n",
       "      <td>Vsi, ki so na tak ali drugačen način zgleduje ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>Lib Demi, ki so obvladovali britansko političn...</td>\n",
       "      <td>Lib Demi, ki je prevladovala na britanski poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>Jaz, robot - ravnokar polni naše kinodvorane -...</td>\n",
       "      <td>jaz, robot - ki pravkar polni naše kinematogra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11311 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  inputs   \n",
       "0      Amsterdam - Le nekaj mesecev potem, ko so nizo...  \\\n",
       "1      \"S trenerjem sva načrtovala uvrstitev v najbol...   \n",
       "2      Najprej zato, ker znajo gledalcem, ki se jih j...   \n",
       "3      Izidi: 1. kolo - skupina A: ZRJ - Grčija 83:72...   \n",
       "4      Tekmovanje se bo pravzaprav začelo že danes z ...   \n",
       "...                                                  ...   \n",
       "11306  Bistvo vsega ni naše telo, temveč telo tehnolo...   \n",
       "11307  Crowley je bil tudi sam umetnik. Za njim je os...   \n",
       "11308  Vsi, ki jih \"prerok Horusovega eona\" tako ali ...   \n",
       "11309  Lib Demi, ki so obvladovali britansko političn...   \n",
       "11310  Jaz, robot - ravnokar polni naše kinodvorane -...   \n",
       "\n",
       "                                                 targets  \n",
       "0      Amsterdam - Le nekaj mesecev po tem, ko so niz...  \n",
       "1      \"S trenerjem sva načrtovala uvrstitev med najb...  \n",
       "2      Najprej zato, ker znajo gledalcem ponuditi, ki...  \n",
       "3      : Rezultati 1 kolo - skupina A: FRY - Grčija 8...  \n",
       "4      Tekmovanje se bo pravzaprav začelo danes z ura...  \n",
       "...                                                  ...  \n",
       "11306  Bistvo vsega ni naše telo, ampak telo tehnolog...  \n",
       "11307  Crowley sam je bil umetnik, ki je zapustil pre...  \n",
       "11308  Vsi, ki so na tak ali drugačen način zgleduje ...  \n",
       "11309  Lib Demi, ki je prevladovala na britanski poli...  \n",
       "11310  jaz, robot - ki pravkar polni naše kinematogra...  \n",
       "\n",
       "[11311 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../data/backtranslate/backtranslate.csv\"\n",
    "\n",
    "data = pd.read_csv(dataset_path, sep=\"\\t\", names=[\"inputs\", \"targets\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraset = ParaDataset(dataset_path, tokenizer, \"parafraziraj: \", max_len)\n",
    "\n",
    "gen = torch.Generator().manual_seed(SEED)\n",
    "train_set, val_set = random_split(paraset, [0.9, 0.1], generator=gen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"./t5\",\n",
    "    overwrite_output_dir=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=500,\n",
    "    #weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
