{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scorerId\n",
      "ocenjevalec3    40\n",
      "ocenjevalec5    40\n",
      "ogjoze          40\n",
      "ocenjevalec6    40\n",
      "joze            40\n",
      "ocenjevalec0    40\n",
      "joze2           40\n",
      "ocenjevalec7    40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../../src/evaluation/\")\n",
    "\n",
    "import eval_backend_handler as ebh\n",
    "\n",
    "df = ebh.get_score_pd()\n",
    "\n",
    "evaluators = [\"joze\", \"joze2\", \"ogjoze\", \"ocenjevalec0\",\n",
    "               \"ocenjevalec3\", \"ocenjevalec5\", \"ocenjevalec6\",\n",
    "               \"ocenjevalec7\"]\n",
    "\n",
    "# keep only valid\n",
    "df = df[df[\"scorerId\"].isin(evaluators)]\n",
    "# only eval\n",
    "df = df[df[\"textId\"].str.startswith(\"evaluation\")]\n",
    "# transform textId to number\n",
    "df[\"textId\"] = df[\"textId\"].apply(lambda x: int(x.split(\"-\")[1]))\n",
    "df = df.drop_duplicates(subset=[\"textId\", \"scorerId\"], keep=\"first\")\n",
    "# everyone should now have 40 scores\n",
    "print(df[\"scorerId\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        appropriateness  fluency  diversity\n",
      "textId                                     \n",
      "0                 1.250    0.375      2.750\n",
      "1                 2.125    0.875      3.000\n",
      "2                 1.625    0.375      3.125\n",
      "3                 2.750    1.125      2.375\n",
      "4                 1.375    0.625      2.875\n",
      "        appropriateness   fluency  diversity\n",
      "textId                                      \n",
      "0              1.281740  0.744024   1.832251\n",
      "1              1.457738  0.991031   0.755929\n",
      "2              1.187735  0.517549   1.125992\n",
      "3              1.281740  1.125992   1.302470\n",
      "4              1.060660  0.744024   0.834523\n"
     ]
    }
   ],
   "source": [
    "per_text_mean = df.groupby(\"textId\")[[\"appropriateness\", \"fluency\", \"diversity\"]].mean()\n",
    "per_text_std = df.groupby(\"textId\")[[\"appropriateness\", \"fluency\", \"diversity\"]].std()\n",
    "print(per_text_mean.head())\n",
    "print(per_text_std.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"baseline\", \"small\", \"large\", \"testset\"]\n",
    "    \n",
    "df[\"model\"] = df[\"textId\"].apply(lambda x: models[x // 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model      |   appropriateness   |       fluency       |      diversity     \n",
      "baseline   | 1.875 +- 1.335      | 0.713 +- 0.944      | 3.038 +- 1.163     \n",
      "small      | 4.375 +- 0.832      | 4.475 +- 0.993      | 1.113 +- 0.914     \n",
      "large      | 4.350 +- 0.748      | 4.475 +- 0.826      | 1.512 +- 1.031     \n",
      "testset    | 4.088 +- 1.034      | 4.450 +- 0.825      | 3.112 +- 1.102     \n"
     ]
    }
   ],
   "source": [
    "per_model_mean = df.groupby(\"model\")[[\"appropriateness\", \"fluency\", \"diversity\"]].mean()\n",
    "per_model_std = df.groupby(\"model\")[[\"appropriateness\", \"fluency\", \"diversity\"]].std()\n",
    "\n",
    "print(f\"{'model':10} | {per_model_mean.columns[0]:^19} | {per_model_mean.columns[1]:^19} | {per_model_mean.columns[2]:^19}\")\n",
    "for model in models:\n",
    "    means = per_model_mean.loc[model].values\n",
    "    stds = per_model_std.loc[model].values\n",
    "    print(f\"{model:10} | {means[0]:.3f} +- {stds[0]:<10.3f} | {means[1]:.3f} +- {stds[1]:<10.3f} | {means[2]:.3f} +- {stds[2]:<10.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = pd.read_csv(\"../testset/baseline_results.csv\", sep=\"\\t\")\n",
    "small_df = pd.read_csv(\"../testset/T5-small_results.csv\", sep=\"\\t\")\n",
    "large_df = pd.read_csv(\"../testset/T5-large_results.csv\", sep=\"\\t\")\n",
    "test_df = pd.read_csv(\"../testset/testset_results.csv\", sep=\"\\t\")\n",
    "\n",
    "eval_set = pd.read_csv(\"eval.csv\", sep=\"\\t\")\n",
    "\n",
    "in_test_idx = eval_set[\"id\"].tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Python\\nlp\\nlp_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mf:\\Python\\nlp\\nlp_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mf:\\Python\\nlp\\nlp_env\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m complete \u001b[39m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m df \u001b[39min\u001b[39;00m [baseline_df, small_df, large_df, test_df]:\n\u001b[1;32m----> 3\u001b[0m     complete\u001b[39m.\u001b[39mappend(df[df[\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39misin(in_test_idx)][\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mtolist())\n",
      "File \u001b[1;32mf:\\Python\\nlp\\nlp_env\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mf:\\Python\\nlp\\nlp_env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "complete = []\n",
    "for df in [baseline_df, small_df, large_df, test_df]:\n",
    "    model_scores = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if row.iloc[0] in in_test_idx:\n",
    "            model_scores.append(row.iloc[3:].tolist())\n",
    "    complete.append(model_scores)\n",
    "complete = np.array(complete)\n",
    "complete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
