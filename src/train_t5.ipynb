{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "\n",
    "checkpoint = \"cjvt/t5-sl-small\"\n",
    "#checkpoint = \"cjvt/t5-sl-large\"\n",
    "\n",
    "max_len = 512 # num of input/output tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joze/Documents/sola/obdelava_naravnega_jezika/nlp-course-taklemamo/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[7477,    1]]), 'attention_mask': tensor([[1, 1]])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer([\"test\"], return_tensors=\"pt\")#游녨"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import pandas as pd\n",
    "\n",
    "class ParaDataset(Dataset):\n",
    "\n",
    "  def __init__(self, fpath, tokenizer, prefix, max_len=512):\n",
    "    super().__init__()\n",
    "    self.raw_data = self._load(fpath)\n",
    "    self.tokenizer = tokenizer\n",
    "    self.prefix = prefix\n",
    "    self.max_len = max_len\n",
    "\n",
    "    self.inputs, self.targets = self._preprocess()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.raw_data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    out = {k:v[index] for k,v in self.inputs.items()}\n",
    "    out[\"labels\"] = self.targets.input_ids[index]\n",
    "    return out\n",
    "\n",
    "  def _load(self, fpath):\n",
    "    return pd.read_csv(fpath, sep=\"\\t\", names=[\"paragraph\", \"paraphrase\"])\n",
    "\n",
    "  def _preprocess(self):\n",
    "    return self._tokenize(self.raw_data.paragraph), self._tokenize(self.raw_data.paraphrase, prefix=False)\n",
    "\n",
    "  def _tokenize(self, text_list, prefix=True):\n",
    "    return self.tokenizer(\n",
    "        [self.prefix + text if prefix else text for text in text_list],\n",
    "        truncation=True, padding=\"max_length\", \n",
    "        max_length=self.max_len, return_tensors=\"pt\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amsterdam - Le nekaj mesecev potem, ko so nizo...</td>\n",
       "      <td>Amsterdam - Le nekaj mesecev po tem, ko so niz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"S trenerjem sva na캜rtovala uvrstitev v najbol...</td>\n",
       "      <td>\"S trenerjem sva na캜rtovala uvrstitev med najb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Najprej zato, ker znajo gledalcem, ki se jih j...</td>\n",
       "      <td>Najprej zato, ker znajo gledalcem ponuditi, ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Izidi: 1. kolo - skupina A: ZRJ - Gr캜ija 83:72...</td>\n",
       "      <td>: Rezultati 1 kolo - skupina A: FRY - Gr캜ija 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tekmovanje se bo pravzaprav za캜elo 쬰 danes z ...</td>\n",
       "      <td>Tekmovanje se bo pravzaprav za캜elo danes z ura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11306</th>\n",
       "      <td>Bistvo vsega ni na코e telo, temve캜 telo tehnolo...</td>\n",
       "      <td>Bistvo vsega ni na코e telo, ampak telo tehnolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11307</th>\n",
       "      <td>Crowley je bil tudi sam umetnik. Za njim je os...</td>\n",
       "      <td>Crowley sam je bil umetnik, ki je zapustil pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11308</th>\n",
       "      <td>Vsi, ki jih \"prerok Horusovega eona\" tako ali ...</td>\n",
       "      <td>Vsi, ki so na tak ali druga캜en na캜in zgleduje ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>Lib Demi, ki so obvladovali britansko politi캜n...</td>\n",
       "      <td>Lib Demi, ki je prevladovala na britanski poli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>Jaz, robot - ravnokar polni na코e kinodvorane -...</td>\n",
       "      <td>jaz, robot - ki pravkar polni na코e kinematogra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11311 rows 칑 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  inputs   \n",
       "0      Amsterdam - Le nekaj mesecev potem, ko so nizo...  \\\n",
       "1      \"S trenerjem sva na캜rtovala uvrstitev v najbol...   \n",
       "2      Najprej zato, ker znajo gledalcem, ki se jih j...   \n",
       "3      Izidi: 1. kolo - skupina A: ZRJ - Gr캜ija 83:72...   \n",
       "4      Tekmovanje se bo pravzaprav za캜elo 쬰 danes z ...   \n",
       "...                                                  ...   \n",
       "11306  Bistvo vsega ni na코e telo, temve캜 telo tehnolo...   \n",
       "11307  Crowley je bil tudi sam umetnik. Za njim je os...   \n",
       "11308  Vsi, ki jih \"prerok Horusovega eona\" tako ali ...   \n",
       "11309  Lib Demi, ki so obvladovali britansko politi캜n...   \n",
       "11310  Jaz, robot - ravnokar polni na코e kinodvorane -...   \n",
       "\n",
       "                                                 targets  \n",
       "0      Amsterdam - Le nekaj mesecev po tem, ko so niz...  \n",
       "1      \"S trenerjem sva na캜rtovala uvrstitev med najb...  \n",
       "2      Najprej zato, ker znajo gledalcem ponuditi, ki...  \n",
       "3      : Rezultati 1 kolo - skupina A: FRY - Gr캜ija 8...  \n",
       "4      Tekmovanje se bo pravzaprav za캜elo danes z ura...  \n",
       "...                                                  ...  \n",
       "11306  Bistvo vsega ni na코e telo, ampak telo tehnolog...  \n",
       "11307  Crowley sam je bil umetnik, ki je zapustil pre...  \n",
       "11308  Vsi, ki so na tak ali druga캜en na캜in zgleduje ...  \n",
       "11309  Lib Demi, ki je prevladovala na britanski poli...  \n",
       "11310  jaz, robot - ki pravkar polni na코e kinematogra...  \n",
       "\n",
       "[11311 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"../data/backtranslate/backtranslate.csv\"\n",
    "\n",
    "data = pd.read_csv(dataset_path, sep=\"\\t\", names=[\"inputs\", \"targets\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paraset = ParaDataset(dataset_path, tokenizer, \"parafraziraj: \", max_len)\n",
    "\n",
    "gen = torch.Generator().manual_seed(SEED)\n",
    "train_set, val_set = random_split(paraset, [0.9, 0.1], generator=gen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= \"./t5\",\n",
    "    overwrite_output_dir=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    warmup_steps=500,\n",
    "    #weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
